dbt Documentation/Guide

1. Installation and Initialization
    Here, we will run pip install dbt-snowflake.
    We will start by installing a Snowflake extension to establish a connection between VS Code (in this case) and Snowflake.
    Then, we will initialize a new dbt project by running dbt init dbt_code.
    This creates a standard-structured directory with the necessary files to start your project.

2 Configure the dbt Profile
Here, we edit .dbt/profiles.yml to fill in Snowflake details such as URL, username, password, etc.
In profiles.yml, you define how dbt should connect to your Snowflake database. This connection allows dbt to authenticate and run SQL queries against your database in Snowflake.

3 Verify the Configuration
    The configuration can be verified by running dbt debug.
    The purpose of this is to ensure that your profiles.yml file is correctly configured for dbt to connect to the database.
    With dbt debug, you can also identify any connection issues to help troubleshoot connection problems.

4 Settings for Visual Studio Code
    Here, we start by installing a dbt extension called "dbt Power User" and modify settings.json by adding:
        "files.associations": {
        ".sql": "jinja-sql",
        ".yml": "jinja-yaml"
    }
    These settings improve coding and usage within VS Code by adding syntax highlighting for dbt-specific files. 
    This makes SQL and YAML files easier to read and understand.

5 dbt Package
    We will add the dbt_utils package to the packages.yml file:
    packages:
    - package: dbt-labs/dbt_utils
        version: 1.2.0
    After that, run dbt deps to initiate the installation of the package.
    The purpose of dbt_utils is to offer helper functions that make it easier for us to write models. 
    With this installation, we gain access to several tools that simplify our dbt work/project.

6 Create the Folder Structure
    By running mkdir src fct dim mart, we create these four folders: src, fct, dim, and mart.
    This is to create an organized folder structure to keep each SQL file in its respective folder.
    This structure facilitates code maintenance and makes it easier for team members to navigate the project.

7 Create and Configure schema.yml
    By creating a schema.yml file in the models folder, we can test our models. 
    Here, we can set up quality control or requirements to ensure that our data meets quality standards.

8 Configure sources.yml
    By creating a sources.yml file in the src folder, we can then configure a connection for where dbt should fetch its raw data.
    In this file, we name the database and specify which schema dbt should search for the raw data.

9 Add dbt_expectations
    In the packages.yml, we should also add dbt_expectations:
        packages:
  - package: calogica/dbt_expectations
    version: 0.10.3
    After that, run dbt deps.
    The purpose of dbt_expectations is that this package tests your data automatically to detect problems.
    With this package, you get a useful tool to ensure data quality by automatically validating data against the requirements.

10 Organize SQL Files in Folders
    Now, when we start creating SQL files, it is important to know where each SQL file should be located:

    src: Raw data from data sources.
    dim: Dimension tables that provide context.
    fct: Fact tables containing key metrics.
    mart: Aggregated data for specific analyses.

    The purpose of this is to make the project more organized, structured, and easier to understand.
    Each folder has a specific purpose, making it easier to understand its role and structure.

11 Run dbt Models
    Now it's time to run dbt run, which executes all models and creates tables in your database.
    Then, run dbt test to run the tests defined in schema.yml to ensure that our data meets quality requirements. 
    This step is important to verify that our models work, are correct, and that the data is reliable.